{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdaea8b-87cd-48e8-9617-59cc34dac6c2",
   "metadata": {
    "id": "2fdaea8b-87cd-48e8-9617-59cc34dac6c2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e47445d-9ffd-4299-8b01-24e0ad91a8b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e47445d-9ffd-4299-8b01-24e0ad91a8b9",
    "outputId": "bc0e6f1a-8612-4ec2-e16a-5669495a15db",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a78666-5a35-4482-a63d-955b28bcbe1d",
   "metadata": {
    "id": "16a78666-5a35-4482-a63d-955b28bcbe1d",
    "tags": []
   },
   "source": [
    "# Linear Layer ([Documentation](http://pytorch.org/docs/stable/generated/torch.nn.Linear.html))\n",
    "``torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dde346-98c7-4e75-9983-bfac4f9e9f64",
   "metadata": {
    "id": "15dde346-98c7-4e75-9983-bfac4f9e9f64"
   },
   "source": [
    "Let us start with a single neuron having 10 inputs and just 1 output, but no bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cbb283-dec1-4100-904b-ec08e83c3a5a",
   "metadata": {
    "id": "37cbb283-dec1-4100-904b-ec08e83c3a5a"
   },
   "source": [
    "## Single Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e17a41-7224-4517-b5da-872702319b4e",
   "metadata": {
    "id": "38e17a41-7224-4517-b5da-872702319b4e"
   },
   "source": [
    "Let us start with a single neuron having 10 input features and just 1 output feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87113a2e-a4bc-4b73-8dd7-e82c0047fac0",
   "metadata": {
    "id": "87113a2e-a4bc-4b73-8dd7-e82c0047fac0"
   },
   "outputs": [],
   "source": [
    "single_neuron = nn.Linear(10, 1, bias = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db7b4f-9d18-402d-9137-bbe2a31e1f3f",
   "metadata": {
    "id": "62db7b4f-9d18-402d-9137-bbe2a31e1f3f"
   },
   "source": [
    "PyTorch automatically ininitializes the weights of all layers, we can look at those weights by calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb93730-ae0f-4f50-8a68-7d5acf750337",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abb93730-ae0f-4f50-8a68-7d5acf750337",
    "outputId": "1e1ce798-f910-4dca-a092-05decf79daee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2796,  0.0697, -0.0067, -0.2011,  0.2039, -0.1499, -0.1548, -0.0609,\n",
      "         -0.2994,  0.0562]], requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(single_neuron.weight)\n",
    "print(single_neuron.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c4080d-d044-4dd0-b061-2ad0c84b9c1e",
   "metadata": {
    "id": "81c4080d-d044-4dd0-b061-2ad0c84b9c1e"
   },
   "source": [
    "An All-Zero Output always evaluates to 0 when there is no bias. Let us verify this by creating a suitable input tensor of ``(b, input_features) == (1, 10)`` with ``b`` being the batch size, ``input_features`` being the number of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eba59bfb-4fdd-4455-834f-b7014f3d3949",
   "metadata": {
    "id": "eba59bfb-4fdd-4455-834f-b7014f3d3949"
   },
   "outputs": [],
   "source": [
    "input_0 = torch.zeros((1, 10))\n",
    "input_1 = torch.ones((1, 10))\n",
    "input_1000 = 1000 * torch.ones((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "750694c7-4a04-4329-9e23-9c05799690e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "750694c7-4a04-4329-9e23-9c05799690e5",
    "outputId": "0ac03e5b-009d-4734-9374-e75c4fb58fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], grad_fn=<MmBackward0>)\n",
      "tensor([[0.3221]], grad_fn=<MmBackward0>)\n",
      "tensor([[322.0690]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(single_neuron(input_0))\n",
    "print(single_neuron(input_1))\n",
    "print(single_neuron(input_1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "mHfA2p6e0_ox",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHfA2p6e0_ox",
    "outputId": "294a61e1-bd18-45c2-a4f5-4a3eff6eb3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3221, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# check the sum of weights\n",
    "print(torch.sum(single_neuron.weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42232bd0-791b-46d0-9cd7-fc9236b2ab05",
   "metadata": {
    "id": "42232bd0-791b-46d0-9cd7-fc9236b2ab05"
   },
   "source": [
    "## Linear Layer with 10 input features and 10 output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9114dd0b-8ab8-4a5c-ac44-6eeb42443b52",
   "metadata": {
    "id": "9114dd0b-8ab8-4a5c-ac44-6eeb42443b52"
   },
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(10, 5, bias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ff14e48-9ac3-43b8-8327-41991bf6d4c9",
   "metadata": {
    "id": "5ff14e48-9ac3-43b8-8327-41991bf6d4c9"
   },
   "outputs": [],
   "source": [
    "linear_input = torch.rand((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b46fcc0e-21e9-4a58-ba90-e23692f572bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b46fcc0e-21e9-4a58-ba90-e23692f572bd",
    "outputId": "15eb3f03-4af6-4289-89c1-4cdaae44f6a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6386, 0.6646, 0.1082, 0.4698, 0.2296]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer(linear_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e52f0-7ea1-44c9-8b59-c9cec3f83e74",
   "metadata": {
    "id": "662e52f0-7ea1-44c9-8b59-c9cec3f83e74"
   },
   "source": [
    "A linear layer is applied to an input tensor by applying a linear transformation of the form $y = xA^T + b$. This can be easily varified by evaluating the equation manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7e9e5dc-cae6-49c2-8756-da1a54c0f2a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7e9e5dc-cae6-49c2-8756-da1a54c0f2a7",
    "outputId": "677e22e7-d52e-4065-f6a3-8549b59dbde0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6386, 0.6646, 0.1082, 0.4698, 0.2296]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(linear_input, linear_layer.weight.T)+linear_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7QLU9bnn1odT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "7QLU9bnn1odT",
    "outputId": "e5db55d6-5a5a-4bdf-ba9c-9bcdd41a628d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "tensor([[0.6386, 0.5418, 0.2708, 0.4533, 0.4407],\n",
      "        [0.7613, 0.6646, 0.3936, 0.5761, 0.5634],\n",
      "        [0.4759, 0.3791, 0.1082, 0.2906, 0.2780],\n",
      "        [0.6551, 0.5583, 0.2873, 0.4698, 0.4572],\n",
      "        [0.4275, 0.3307, 0.0598, 0.2423, 0.2296]], grad_fn=<AddBackward0>)\n",
      "tensor([[0.6386, 0.5418, 0.2708, 0.4533, 0.4407],\n",
      "        [0.7613, 0.6646, 0.3936, 0.5761, 0.5634],\n",
      "        [0.4759, 0.3791, 0.1082, 0.2906, 0.2780],\n",
      "        [0.6551, 0.5583, 0.2873, 0.4698, 0.4572],\n",
      "        [0.4275, 0.3307, 0.0598, 0.2423, 0.2296]], grad_fn=<AddBackward0>)\n",
      "tensor([[0.6386],\n",
      "        [0.6646],\n",
      "        [0.1082],\n",
      "        [0.4698],\n",
      "        [0.2296]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5x10 and 1x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m( torch\u001b[38;5;241m.\u001b[39mmm(linear_layer\u001b[38;5;241m.\u001b[39mweight, linear_input\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m linear_layer\u001b[38;5;241m.\u001b[39mbias)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m( torch\u001b[38;5;241m.\u001b[39mmm(linear_layer\u001b[38;5;241m.\u001b[39mweight, linear_input\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m linear_layer\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m) ) \u001b[38;5;66;03m#only working line of code\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_input\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m linear_layer\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5x10 and 1x10)"
     ]
    }
   ],
   "source": [
    "# easy to produce errors with wrong layout\n",
    "print( linear_layer.bias.shape)\n",
    "print( torch.mm(linear_layer.weight, linear_input.T) + linear_layer.bias.T )\n",
    "print( torch.mm(linear_layer.weight, linear_input.T) + linear_layer.bias)\n",
    "print( torch.mm(linear_layer.weight, linear_input.T) + linear_layer.bias.reshape(5,1) ) #only working line of code\n",
    "\n",
    "print( torch.mm(linear_layer.weight, linear_input) + linear_layer.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a_3fkgG82Qfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_3fkgG82Qfa",
    "outputId": "94032a6c-b3c1-4ba5-d342-79dba50e075a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6385689 ],\n",
       "       [0.664554  ],\n",
       "       [0.10815333],\n",
       "       [0.46982756],\n",
       "       [0.22959767]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy verification\n",
    "\n",
    "np.dot( linear_layer.weight.detach().numpy(), linear_input.T.detach().numpy()) + linear_layer.bias.reshape(5,1).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaaa2c5-be60-4bd1-8fb2-2db4b3078933",
   "metadata": {
    "id": "cbaaa2c5-be60-4bd1-8fb2-2db4b3078933"
   },
   "source": [
    "## Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b961f-e8e3-460b-951b-cda531f790e3",
   "metadata": {
    "id": "b29b961f-e8e3-460b-951b-cda531f790e3"
   },
   "source": [
    "A Neural Network consisting of more than one linear layer (also referred to as Fully Connected Layer) is also called a Multi Layer Perceptron (MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6f8a763-a458-4a1e-b4e0-d55615cd0493",
   "metadata": {
    "id": "a6f8a763-a458-4a1e-b4e0-d55615cd0493"
   },
   "outputs": [],
   "source": [
    "# often a neural network is defined as object derived from \"nn.Module\"\n",
    "# we would like to define an \"__init__\" and \"forward\" function\n",
    "\n",
    "class ThreeLayerMLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, output_features):\n",
    "        super(ThreeLayerMLP, self).__init__()\n",
    "        self.layer_0 = nn.Linear(in_features = input_features, out_features = hidden_features)\n",
    "        self.layer_1 = nn.Linear(in_features = hidden_features, out_features = hidden_features)\n",
    "        self.layer_2 = nn.Linear(in_features = hidden_features, out_features = output_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_0(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb236539-8c01-4b8b-aa8f-70dbc69c223a",
   "metadata": {
    "id": "cb236539-8c01-4b8b-aa8f-70dbc69c223a"
   },
   "outputs": [],
   "source": [
    "my_mlp = ThreeLayerMLP(10, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a59058f-a8ce-46e9-804c-fc45cb49377c",
   "metadata": {
    "id": "5a59058f-a8ce-46e9-804c-fc45cb49377c"
   },
   "outputs": [],
   "source": [
    "mlp_input = torch.rand((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df2837fe-98c3-4b29-93bc-ff51781b68f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df2837fe-98c3-4b29-93bc-ff51781b68f6",
    "outputId": "17593bf7-79b5-4d1d-9783-e4db05209d3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2671]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp(mlp_input) # this calls the forward function; handles distribution on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "pCVvaf635ryz",
   "metadata": {
    "id": "pCVvaf635ryz"
   },
   "outputs": [],
   "source": [
    "# add activation functions\n",
    "# \n",
    "\n",
    "class ThreeLayerMLPNew(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, output_features):\n",
    "        super(ThreeLayerMLPNew, self).__init__()\n",
    "        self.layer_0 = nn.Linear(in_features = input_features, out_features = hidden_features)\n",
    "        self.layer_1 = nn.Linear(in_features = hidden_features, out_features = hidden_features)\n",
    "        self.layer_2 = nn.Linear(in_features = hidden_features, out_features = output_features)\n",
    "        self.relu = nn.ReLU() # only defined once not three times / depends on coding style / better to define layer for each use\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4KwNxZ-6icE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4KwNxZ-6icE",
    "outputId": "1b497117-dd2b-43ca-b859-4dbe0c5acefd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0154]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute multiple times to see that output never gets < 0\n",
    "\n",
    "my_mlpnew = ThreeLayerMLPNew(3, 3, 1)\n",
    "mlp_input = torch.rand((1, 3))\n",
    "my_mlpnew(mlp_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae360e61-058f-4204-ae1b-5b67083e5005",
   "metadata": {
    "id": "ae360e61-058f-4204-ae1b-5b67083e5005"
   },
   "source": [
    "# Conv2d Layer ([Documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html))\n",
    "``torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c074bcf-e7fe-412c-9ab8-bd25d1b6eac3",
   "metadata": {
    "id": "7c074bcf-e7fe-412c-9ab8-bd25d1b6eac3"
   },
   "outputs": [],
   "source": [
    "conv_input = torch.randn(1, 3, 9, 9) # batch_size == 1, num_channels == 3, height == 9, width == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c07f7615-3902-47bf-906b-06c128bb47b7",
   "metadata": {
    "id": "c07f7615-3902-47bf-906b-06c128bb47b7"
   },
   "outputs": [],
   "source": [
    "# With square 3x3 kernels\n",
    "m = nn.Conv2d(3, 1, 3, stride = 1, padding = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14ad7a97-ddd9-4bd5-ad28-16ac9c6e34e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14ad7a97-ddd9-4bd5-ad28-16ac9c6e34e6",
    "outputId": "7a884980-39fe-4bf4-9c79-c234b14b0200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 9, 9])\n",
      "tensor([[[[-0.0688,  1.0080, -0.1952, -0.4213,  1.2057,  0.0352,  0.3721,\n",
      "           -0.7106,  0.6480],\n",
      "          [ 0.3263, -1.1588,  0.7259, -0.0271,  1.2648, -0.8364,  0.0496,\n",
      "            1.6218, -0.6744],\n",
      "          [-0.2796,  0.4528, -0.0030,  0.3925,  0.7096, -0.0309,  0.0199,\n",
      "            0.3052,  0.7400],\n",
      "          [ 0.2252,  0.1637, -0.1927,  0.8032,  0.8487, -0.1268, -0.1083,\n",
      "           -0.5677, -0.1207],\n",
      "          [-0.1011, -0.3054,  1.5335,  0.0322, -0.6163,  0.1893,  0.5967,\n",
      "           -0.3229, -0.3054],\n",
      "          [ 0.3376,  0.0649, -0.5177,  0.4741,  0.7551, -0.4433, -0.2757,\n",
      "            0.1929,  0.1562],\n",
      "          [ 0.8507, -0.1239,  0.6604,  0.1699, -1.7184,  0.3322,  0.9810,\n",
      "            0.6598, -0.1032],\n",
      "          [ 0.4704,  1.1027,  0.0681, -0.8049, -0.2732,  0.2082,  0.4457,\n",
      "           -0.2880, -0.4796],\n",
      "          [ 0.2129, -0.7431, -1.0015,  0.9351,  0.2950,  0.4925,  0.3716,\n",
      "            0.2472,  0.0209]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = m(conv_input)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44ce155a-c89b-471d-9d1e-166491b3c73e",
   "metadata": {
    "id": "44ce155a-c89b-471d-9d1e-166491b3c73e"
   },
   "outputs": [],
   "source": [
    "# With square 3x3 kernels and stride 2\n",
    "m = nn.Conv2d(3, 1, 3, stride =  2, padding = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0df43ac-4a5d-4632-a388-94e7a477b3cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0df43ac-4a5d-4632-a388-94e7a477b3cd",
    "outputId": "3faab113-2264-4d7a-f89a-a48434d5f034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "tensor([[[[ 0.7016, -0.4116,  0.5285, -0.2563, -0.1253],\n",
      "          [ 0.2424,  0.0719,  0.1447,  0.5472, -0.0517],\n",
      "          [-0.5323,  0.9849, -0.1615,  0.7256,  0.7983],\n",
      "          [ 0.1683,  1.2420, -1.2064,  1.2024,  0.5533],\n",
      "          [ 0.0993, -0.6590,  0.4505,  0.6603,  0.5297]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = m(conv_input)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b0184-d73f-404d-afef-0df4b9ba936b",
   "metadata": {
    "id": "d98b0184-d73f-404d-afef-0df4b9ba936b"
   },
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9b2a6-fcc4-415f-a3ec-990c033354cd",
   "metadata": {
    "id": "3df9b2a6-fcc4-415f-a3ec-990c033354cd"
   },
   "source": [
    "A Neural Network that only consists of convolutional layers is also referred to as a convolutional neural network. The big advantage is that the input size can vary as it only has to have the right number of input channels but the spatial height and width can vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b211cf96-c24a-46c5-be48-093641fcd09c",
   "metadata": {
    "id": "b211cf96-c24a-46c5-be48-093641fcd09c"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer_0 = nn.Conv2d(in_channels = input_channels, out_channels = hidden_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.relu0 = nn.ReLU()\n",
    "        self.layer_1 = nn.Conv2d(in_channels = hidden_channels, out_channels = hidden_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer_2 = nn.Conv2d(in_channels = hidden_channels, out_channels = output_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_0(x)\n",
    "        x = self.relu0( x )\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu1( x )\n",
    "        x = self.layer_2(x)\n",
    "        x = self.relu2( x )\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a799063-0455-484b-a51b-1d403819dc70",
   "metadata": {
    "id": "2a799063-0455-484b-a51b-1d403819dc70"
   },
   "outputs": [],
   "source": [
    "conv_net = nn.Conv2d(3, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "459af3f6-f85f-49cb-80e4-b9a8084823ed",
   "metadata": {
    "id": "459af3f6-f85f-49cb-80e4-b9a8084823ed"
   },
   "outputs": [],
   "source": [
    "conv_input_small = torch.rand((1, 3, 16, 16)) # batch_size == 1, num_channels == 3, height == 16, width == 16\n",
    "conv_input_large = torch.rand((1, 3, 32, 32)) # batch_size == 1, num_channels == 3, height == 32, width == 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f148f90e-03a7-4f30-943b-7a465b438219",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f148f90e-03a7-4f30-943b-7a465b438219",
    "outputId": "4bc03b65-f569-4dfa-8afa-91bc736dbecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 16, 16])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(conv_net(conv_input_small).shape)\n",
    "print(conv_net(conv_input_large).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d0042b-cbaf-4e49-a7f3-5d750881a970",
   "metadata": {
    "id": "f2d0042b-cbaf-4e49-a7f3-5d750881a970"
   },
   "source": [
    "## Conv-Net with FC Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a12ec-d17a-4e90-99d6-d37a49184deb",
   "metadata": {
    "id": "578a12ec-d17a-4e90-99d6-d37a49184deb"
   },
   "source": [
    "In practice, Neural Networks often consist of a combination of different layer types like Conv2d and Linear. A linear layer is often used in the very end of a classifier network to obtain the right number of image classes. The network can therefore handle only on particular input image resolution. Let us define a classifier that takes RGB images (3 channels) of size 32x32 as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b2bcb65-0131-4d59-a032-a7924cb29340",
   "metadata": {
    "id": "1b2bcb65-0131-4d59-a032-a7924cb29340"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module): \n",
    "    def __init__(self, input_channels, hidden_channels, num_output_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.conv_part = ConvNet(input_channels, hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.fc_layer = nn.Linear(in_features = 3 * 32 * 32, out_features = num_output_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_part(x)\n",
    "        x = torch.flatten(x, start_dim = 1) # Reshape to a single vector of size (3 * 32 * 32)\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64eb9d89-d4a9-41bb-921e-f9d4ca5194a7",
   "metadata": {
    "id": "64eb9d89-d4a9-41bb-921e-f9d4ca5194a7"
   },
   "outputs": [],
   "source": [
    "classifier = Classifier(3, 3, 10)\n",
    "good_input = torch.rand((1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b0dac8a-b212-4fea-8615-88871dfd35c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b0dac8a-b212-4fea-8615-88871dfd35c4",
    "outputId": "d7139e8b-e673-41a5-8cb4-29291fd68015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(classifier(good_input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0de77a06-985e-4f32-89a8-1caab1bf9883",
   "metadata": {
    "id": "0de77a06-985e-4f32-89a8-1caab1bf9883"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x768 and 3072x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m bad_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbad_input\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_part(x)\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, start_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Reshape to a single vector of size (3 * 32 * 32)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x768 and 3072x10)"
     ]
    }
   ],
   "source": [
    "bad_input = torch.rand((1, 3, 16, 16))\n",
    "print(classifier(bad_input).shape) # This does not work because the Classifier contains a fully-connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0261ce31-a619-4a5e-8a62-c7ada72db655",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* Randomly initialise weight\n",
    "* Implement forward propagation to get ) for any\n",
    "* Implement backprop to compute partial derivatives\n",
    "* For all the samples, perform forward propagation and\n",
    "backpropagation\n",
    "* Using numerical estimation of gradient to check the gradient\n",
    "calculation, disable after checking\n",
    "* Use gradient descent or advanced optimization method with\n",
    "backpropagation to try to minimize cost function"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
