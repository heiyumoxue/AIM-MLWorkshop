{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_linear_model(torch.nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        super(my_linear_model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input, output)\n",
    "    def forward(self, x):\n",
    "        output = self.linear(x)\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function is extremely useful for two main reasons:\n",
    "\n",
    "    * It transforms our linear regression output to a probability from 0 to 1. We can then take any probability greater than 0.5 as being 1 and below as being 0.\n",
    "    * Unlike a stepwise function (which would transform the data into the binary case as well), the sigmoid is differentiable, which is necessary for optimizing the parameters using gradient descent (we will show later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200000\n",
    "input_dim = 2 # Two inputs x1 and x2 \n",
    "output_dim = 1 # Single binary output \n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  my_linear_model(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/zli3/Documents/AIM-MLWorkshop/w4/regression.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/zli3/Documents/AIM-MLWorkshop/w4/regression.ipynb#ch0000011?line=0'>1</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zli3/Documents/AIM-MLWorkshop/w4/regression.ipynb#ch0000011?line=1'>2</a>\u001b[0m  inputs, labels, test_size\u001b[39m=\u001b[39m\u001b[39m0.33\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "X_train, X_test, y_train, y_test = sklearn.train_test_split(\n",
    " inputs, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/zli3/Documents/AIM-MLWorkshop/w4/regression.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/zli3/Documents/AIM-MLWorkshop/w4/regression.ipynb#ch0000010?line=0'>1</a>\u001b[0m X_train, X_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(X_train),torch\u001b[39m.\u001b[39mTensor(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zli3/Documents/AIM-MLWorkshop/w4/regression.ipynb#ch0000010?line=1'>2</a>\u001b[0m y_train, y_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(y_train),torch\u001b[39m.\u001b[39mTensor(y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test = torch.Tensor(X_train),torch.Tensor(X_test)\n",
    "y_train, y_test = torch.Tensor(y_train),torch.Tensor(y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28bd5159ee8533946d28d32628c124790dab52c3fb94b18f811aadd9b3686beb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
